project:
  name: transformer-fine-tuning
  version: "1.0.0"
  seed: 42


model:
  encoder_only:
    model_name: "bert-base-uncased"
    tokenizer_name: "bert-base-uncased"
    num_labels: 2
    model_dir: "./artifacts/model"
    tokenizer_dir: "./artifacts/tokenizer"


training:
  batch_size: 16
  epochs: 5
  learning_rate: 2e-5
  weight_decay: 0.01
  optimizer: AdamW
  scheduler: linear

data:
  train_path: data/train.csv
  valid_path: data/valid.csv
  test_path: data/test.csv
  max_length: 256

logging:
  save_dir: outputs/logs
  log_interval: 50
  save_checkpoints: true

device:
  use_gpu: true
  gpu_id: 0
